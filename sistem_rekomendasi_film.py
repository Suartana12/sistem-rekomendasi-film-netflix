# -*- coding: utf-8 -*-
"""Sistem Rekomendasi Film.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15mT69rKtDeWyYE_BYYNf6W-kvcTSHeSx

# **Proyek Machine Learning: Sistem Rekomendasi Film Netflix**

Proyek ini bertujuan untuk membangun sebuah model sistem rekomendasi film untuk platform Netflix, dengan menerapkan pendekatan Content-Based Filtering. Analisis ini akan membantu pengguna menemukan film baru yang sesuai dengan selera mereka, sehingga dapat meningkatkan pengalaman dan keterlibatan (engagement) pengguna.
"""

# Instal library Kaggle
!pip install -q kaggle

# Impor library untuk mengunggah file
from google.colab import files

# Buat direktori untuk menyimpan file kaggle.json
!mkdir -p ~/.kaggle

# Unggah file kaggle.json
print("Silakan unggah file kaggle.json Anda:")
uploaded = files.upload()

# Pindahkan file ke direktori yang benar dan atur izin
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

print("\nSetup Kaggle API selesai.")

"""## **Import Library**"""

# --- Library untuk Data Manipulation ---
import pandas as pd
import numpy as np
import json

# --- Library untuk Visualisasi Data ---
import seaborn as sns
import matplotlib.pyplot as plt

# --- Library untuk Machine Learning (Sistem Rekomendasi) ---
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# --- Library lainnya ---
import zipfile
import os

print("Semua library yang dibutuhkan telah berhasil diimpor.")

"""## **A. Data Loading**
Dataset yang digunakan adalah "Netflix Movies and TV Shows" dari Kaggle, yang berisi daftar film dan acara TV yang tersedia di Netflix.
"""

# Download dataset dari Kaggle
!kaggle datasets download -d shivamb/netflix-shows

# Ekstrak file zip yang telah diunduh
with zipfile.ZipFile('netflix-shows.zip', 'r') as zip_ref:
    zip_ref.extractall('netflix_dataset')

# Muat dataset ke dalam DataFrame pandas
df = pd.read_csv('netflix_dataset/netflix_titles.csv')

print("Dataset berhasil diunduh dan dimuat.")

# Tampilkan 5 baris pertama dari dataset
df.head()

# Tampilkan informasi ringkas mengenai dataset
df.info()

"""## **B. Exploratory Data Analysis (EDA)**
Pada tahap ini, dilakukan analisis lebih dalam menggunakan visualisasi data untuk menemukan pola dan wawasan dari dataset Netflix.

### **Analisis Kualitas Data**
Langkah pertama dalam EDA adalah memahami kualitas data. Ini termasuk memeriksa data duplikat dan nilai yang hilang (missing values) untuk mengetahui seberapa bersih data awal kita dan apakah diperlukan langkah-langkah pembersihan data.
"""

# Pengecekan Data Duplikat
duplicate_rows = df.duplicated().sum()
print(f"Jumlah baris duplikat dalam dataset: {duplicate_rows}")

# Pengecekan Nilai yang Hilang (Missing Values)
print("\nJumlah nilai hilang per kolom:")
print(df.isnull().sum())

"""### **Temuan dari Analisis Kualitas Data**

Dari pengecekan kualitas data di atas, ditemukan beberapa poin penting:
* [cite_start]**Data Duplikat**: Tidak ada baris data yang terduplikasi dalam dataset (**0 baris duplikat**).
* **Nilai Hilang (Missing Values)**: Terdapat beberapa kolom dengan jumlah nilai kosong yang signifikan, yaitu:
    * [cite_start]`director`: 2.634 nilai kosong
    * `cast`: 825 nilai kosong
    * `country`: 831 nilai kosong
    * [cite_start]`date_added`: 10 nilai kosong
    * `rating`: 4 nilai kosong
    * `duration`: 3 nilai kosong

[cite_start]Informasi ini sangat penting karena menunjukkan bahwa kita perlu menangani nilai-nilai yang hilang ini, terutama pada kolom yang akan digunakan sebagai fitur (`director`, `cast`, `rating`), pada tahap *Data Preparation*.

### **Analisis Univariate: Distribusi Genre**
Selanjutnya, kita akan memeriksa distribusi genre untuk memahami fokus konten yang paling banyak tersedia di Netflix. [cite_start]Hal ini akan memberikan konteks terhadap jenis film yang kemungkinan besar akan direkomendasikan.
"""

# Mengambil data genre dan memisahkannya
genres = df['listed_in'].str.split(', ', expand=True).stack()

# Menghitung frekuensi setiap genre
plt.figure(figsize=(12, 8))
sns.countplot(y=genres, order=genres.value_counts().index[:15], palette='viridis')
plt.title('Top 15 Genre Konten di Netflix', fontsize=16)
plt.xlabel('Jumlah Konten', fontsize=12)
plt.ylabel('Genre', fontsize=12)
plt.show()

"""### **Wawasan dari Distribusi Genre**

Grafik di atas menampilkan 15 genre konten teratas di Netflix. Dari visualisasi tersebut, dapat ditarik beberapa kesimpulan:
* Genre **"International Movies"** dan **"Dramas"** merupakan dua kategori yang paling mendominasi. [cite_start]Ini mengindikasikan bahwa sebagian besar konten yang tersedia adalah film internasional dan drama.
* Genre **"Comedies"** juga menempati posisi yang tinggi, menunjukkan popularitasnya di kalangan pengguna.
* [cite_start]Distribusi ini memberikan gambaran umum mengenai fokus konten yang ada di platform, yang nantinya akan memengaruhi hasil rekomendasi.

### **Analisis Univariate: Distribusi Rating**
[cite_start] Analisis ini bertujuan untuk melihat bagaimana konten didistribusikan berdasarkan rating usia.
"""

plt.figure(figsize=(12, 6))
sns.countplot(x='rating', data=df, order=df['rating'].value_counts().index, palette='magma')
plt.title('Distribusi Konten Berdasarkan Rating Usia', fontsize=16)
plt.xlabel('Rating', fontsize=12)
plt.ylabel('Jumlah Konten', fontsize=12)
plt.xticks(rotation=45)
plt.show()

"""### **Wawasan dari Distribusi Rating**

Visualisasi distribusi rating usia menunjukkan bahwa:
* Rating **"TV-MA"** (untuk penonton dewasa) memiliki jumlah konten tertinggi, diikuti oleh **"TV-14"** (untuk penonton 14 tahun ke atas).
* [cite_start]Hal ini menandakan bahwa sebagian besar konten Netflix ditujukan untuk audiens remaja dan dewasa.
* [cite_start]Pemahaman tentang distribusi rating ini penting untuk konteks penggunaan sistem rekomendasi, meskipun rating tidak dijadikan fitur utama dalam model *Content-Based Filtering* pada proyek ini.

## **C. Data Preparation**

### **Menangani Nilai yang Hilang dan Membuat DataFrame Baru**
Pada tahap ini, kita akan fokus pada konten bertipe **"Movie"** untuk membangun sistem rekomendasi film. [cite_start]Selain itu, nilai yang hilang pada kolom-kolom fitur utama (`director`, `cast`, `country`, `rating`, `description`) akan diisi dengan string kosong agar dapat diproses pada tahap pemodelan.
"""

# Fokus pada tipe 'Movie' untuk rekomendasi film
df_movies = df[df['type'] == 'Movie'].copy()

# [REVISI] Menampilkan jumlah baris sebelum dan sesudah filter
print(f"Jumlah baris data awal: {df.shape[0]}")
print(f"Jumlah baris setelah difilter hanya untuk 'Movie': {df_movies.shape[0]}")

# Mengisi nilai null pada kolom yang akan digunakan
features_to_fill = ['director', 'cast', 'country', 'rating', 'description']
for feature in features_to_fill:
    df_movies[feature] = df_movies[feature].fillna('')

# Membuat DataFrame baru yang hanya berisi kolom esensial
new_df = df_movies[['show_id', 'title', 'director', 'cast', 'listed_in', 'description']].copy()
new_df.rename(columns={'show_id': 'id', 'listed_in': 'genres'}, inplace=True)

new_df.head()

"""[cite_start]Setelah pemfilteran, kita sekarang memiliki **6131 data film** yang akan digunakan untuk membuat model sistem rekomendasi.  Kolom-kolom dengan nilai yang hilang juga telah dibersihkan.

### **Pembersihan dan Penggabungan Fitur Teks**
Untuk model *Content-Based Filtering*, kita perlu membuat sebuah "kantong kata" (bag of words) atau metadata gabungan yang merepresentasikan setiap film. Fitur-fitur seperti `director`, `cast`, `genres`, dan `description` akan digabungkan menjadi satu kolom teks baru yang disebut `tags`.
"""

# Fungsi untuk membersihkan dan menggabungkan teks
def clean_and_combine(row):
    # Menghapus spasi dan mengubah menjadi list
    director = [d.replace(" ", "") for d in row['director'].split(', ')]
    cast = [c.replace(" ", "") for c in row['cast'].split(', ')[:3]] # Ambil 3 pemeran utama
    genres = [g.replace(" ", "") for g in row['genres'].split(', ')]
    description = row['description'].split()

    # Gabungkan semua fitur menjadi satu list
    tags = director + cast + genres + description
    return " ".join(tags)

# Terapkan fungsi untuk membuat kolom 'tags'
new_df['tags'] = new_df.apply(clean_and_combine, axis=1)

# Membuat DataFrame akhir untuk pemodelan
final_df = new_df[['id', 'title', 'tags']]

# Reset indeks agar berurutan dari 0 hingga n-1
final_df.reset_index(drop=True, inplace=True)

final_df.head()

# Tampilkan contoh isi kolom 'tags' untuk satu film
print("Contoh isi kolom 'tags' untuk film pertama:\n")
print(final_df.iloc[0].tags)

"""## **D. Modeling and Result**

### **Model Pertama: Content-Based Filtering dengan TF-IDF**
Model pertama menggunakan **TF-IDF (Term Frequency-Inverse Document Frequency)** untuk mengubah data teks (`tags`) menjadi vektor numerik. TF-IDF akan memberikan bobot yang lebih tinggi pada kata-kata yang sering muncul dalam satu film tetapi jarang muncul di film lain, sehingga dianggap lebih signifikan.
"""

# Inisialisasi TfidfVectorizer
tfidf = TfidfVectorizer(max_features=5000, stop_words='english')

# Melakukan fit dan transform pada kolom 'tags'
vectors_tfidf = tfidf.fit_transform(final_df['tags']).toarray()

# Menghitung cosine similarity
similarity_tfidf = cosine_similarity(vectors_tfidf)

# Fungsi rekomendasi untuk model TF-IDF
def recommend_tfidf(movie_title):
    try:
        movie_index = final_df[final_df['title'] == movie_title].index[0]
    except IndexError:
        print(f"Film dengan judul '{movie_title}' tidak ditemukan.")
        return

    distances = similarity_tfidf[movie_index]
    movies_list = sorted(list(enumerate(distances)), reverse=True, key=lambda x: x[1])[1:6]

    print(f"Rekomendasi film mirip '{movie_title}' (berdasarkan TF-IDF):")
    for i in movies_list:
        print(final_df.iloc[i[0]].title)

# Pengujian Model Pertama
recommend_tfidf('The Social Network')

"""### **Model Kedua: Content-Based Filtering dengan CountVectorizer**
Model kedua menggunakan **CountVectorizer (Bag of Words)**. Berbeda dengan TF-IDF, CountVectorizer hanya menghitung frekuensi kemunculan setiap kata tanpa memperhitungkan seberapa sering kata itu muncul di seluruh dokumen. [cite_start]Pendekatan ini lebih sederhana.
"""

# Inisialisasi CountVectorizer
count_vec = CountVectorizer(max_features=5000, stop_words='english')
vectors_bow = count_vec.fit_transform(final_df['tags']).toarray()

# Menghitung cosine similarity
similarity_bow = cosine_similarity(vectors_bow)

# Fungsi rekomendasi untuk model Bag of Words
def recommend_bow(movie_title):
    try:
        movie_index = final_df[final_df['title'] == movie_title].index[0]
    except IndexError:
        print(f"Film dengan judul '{movie_title}' tidak ditemukan.")
        return

    distances = similarity_bow[movie_index]
    movies_list = sorted(list(enumerate(distances)), reverse=True, key=lambda x: x[1])[1:6]

    print(f"Rekomendasi film mirip '{movie_title}' (berdasarkan Bag of Words):")
    for i in movies_list:
        print(final_df.iloc[i[0]].title)

# Pengujian Model Kedua
recommend_bow('The Social Network')

"""## **E. Evaluation**
Untuk mengevaluasi kedua model, kita akan menggunakan metrik **Precision**. Precision akan dihitung berdasarkan kesamaan genre antara film input dengan film-film yang direkomendasikan. Sebuah rekomendasi dianggap relevan jika memiliki setidaknya satu genre yang sama dengan film input.

### **Langkah 1 & 2: Modifikasi Fungsi Rekomendasi & Membuat Fungsi Evaluasi**
Fungsi rekomendasi dimodifikasi untuk mengembalikan list judul, dan fungsi evaluasi dibuat untuk menghitung presisi.
"""

# Fungsi untuk mendapatkan list rekomendasi (TF-IDF)
def get_recommendations_tfidf(movie_title):
    try:
        movie_index = final_df[final_df['title'] == movie_title].index[0]
    except IndexError:
        return []
    distances = similarity_tfidf[movie_index]
    movies_list = sorted(list(enumerate(distances)), reverse=True, key=lambda x: x[1])[1:6]
    return [final_df.iloc[i[0]].title for i in movies_list]

# Fungsi untuk mendapatkan list rekomendasi (Bag of Words)
def get_recommendations_bow(movie_title):
    try:
        movie_index = final_df[final_df['title'] == movie_title].index[0]
    except IndexError:
        return []
    distances = similarity_bow[movie_index]
    movies_list = sorted(list(enumerate(distances)), reverse=True, key=lambda x: x[1])[1:6]
    return [final_df.iloc[i[0]].title for i in movies_list]

# Fungsi untuk menghitung precision berdasarkan kesamaan genre
def calculate_precision(input_title, recommended_titles):
    try:
        # Menggunakan df_movies yang masih memiliki kolom 'listed_in' asli
        input_genres = set(df_movies[df_movies['title'] == input_title]['listed_in'].iloc[0].split(', '))
    except IndexError:
        print(f"Film input '{input_title}' tidak ditemukan.")
        return 0.0

    if not recommended_titles:
        return 0.0

    relevant_count = 0
    for title in recommended_titles:
        try:
            rec_genres = set(df_movies[df_movies['title'] == title]['listed_in'].iloc[0].split(', '))
            # Jika ada irisan genre, dianggap relevan
            if input_genres.intersection(rec_genres):
                relevant_count += 1
        except IndexError:
            continue

    return relevant_count / len(recommended_titles)

"""### **Langkah 3: Mengevaluasi Kinerja Kedua Model**
Kita akan menguji kedua model menggunakan film "The Social Network" sebagai input dan menghitung nilai Precision@5 (presisi untuk 5 rekomendasi teratas).
"""

# Film yang akan diuji
test_movie = 'The Social Network'

# --- Evaluasi Model 1 (TF-IDF) ---
recs_tfidf = get_recommendations_tfidf(test_movie)
precision_tfidf = calculate_precision(test_movie, recs_tfidf)

print(f"Rekomendasi dari TF-IDF untuk '{test_movie}': {recs_tfidf}")
print(f"Precision @5 untuk model TF-IDF: {precision_tfidf:.2f}\n")

# --- Evaluasi Model 2 (Bag of Words) ---
recs_bow = get_recommendations_bow(test_movie)
precision_bow = calculate_precision(test_movie, recs_bow)

print(f"Rekomendasi dari Bag of Words untuk '{test_movie}': {recs_bow}")
print(f"Precision @5 untuk model Bag of Words: {precision_bow:.2f}")

"""## **Analisis Hasil Evaluasi**

Hasil pengujian pada film "The Social Network" (genre: Dramas, Independent Movies) menunjukkan perbedaan kinerja yang signifikan antara kedua model.

**Model 1: TF-IDF**

* Rekomendasi: ['The Music of Silence', 'Nothing to Lose', 'The End of the Tour', 'Justin Timberlake + the Tennessee Kids', 'Tiffany Haddish: She Ready! From the Hood To Hollywood!']
* Nilai Presisi: Model ini mencapai Precision@5 sebesar 0.60.

**Model 2: Bag of Words (CountVectorizer)**

* Rekomendasi: ['Nothing to Lose', 'The Music of Silence', 'The End of the Tour', 'Ani... Dr. Kashinath Ghanekar', 'Curtiz']
* Nilai Presisi: Model ini mencapai Precision@5 sebesar 1.00.

**Perbandingan dan Wawasan**

1.   **Kinerja Model**: Dalam kasus uji ini, model Bag of Words (CountVectorizer) secara jelas memberikan hasil yang lebih baik daripada model TF-IDF. Presisinya sempurna, menunjukkan relevansi genre yang lebih tinggi.
2.   **Alasan Perbedaan Kinerja**: Perbedaan ini kemungkinan besar disebabkan oleh cara kedua metode membobot kata. TF-IDF memberikan bobot lebih tinggi pada kata-kata yang jarang muncul di seluruh dokumen. Ada kemungkinan kata seperti "music" atau "stand-up" memiliki bobot TF-IDF yang tinggi dalam deskripsi atau tag film tertentu, yang mendorongnya ke atas dalam peringkat rekomendasi meskipun genrenya tidak cocok. Sebaliknya, CountVectorizer hanya menghitung frekuensi kata, sehingga fitur-fitur umum yang kuat seperti nama sutradara/aktor dan genre "Drama" lebih mendominasi perhitungan kemiripan, menghasilkan rekomendasi yang lebih konsisten secara tematik.

Secara keseluruhan, evaluasi ini menunjukkan bahwa untuk dataset dan kombinasi fitur ini, pendekatan yang lebih sederhana (Bag of Words) ternyata lebih efektif dalam menghasilkan rekomendasi yang relevan secara genre.
"""